{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-ugYIZG_vwU"
      },
      "source": [
        "# Read dataset and create data loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "sUdX_1lQ7Zf8"
      },
      "outputs": [],
      "source": [
        "# Import torch and CIFAR dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Import matplotlib and numpy for graphs\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "Dy0dXGIAAs-N"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size: 64\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Import CIFAR dataset, define labbels and load training and validation dataset\n",
        "Reference for loading dataset: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
        "Reference for augmentation: https://pytorch.org/vision/stable/transforms.html\n",
        "'''\n",
        "batch_size=64\n",
        "print('Batch size:', batch_size)\n",
        "\n",
        "# Normalisation and std values for RGB in dataset\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "# Data augmentation for training set\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),  # Randomly crop the image with padding\n",
        "    transforms.RandomHorizontalFlip(),    # Randomly flip the image horizontally\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Adjust brightness, contrast, etc.\n",
        "    transforms.RandomRotation(15),        # Randomly rotate the image by up to 15 degrees\n",
        "    transforms.ToTensor(),                # Convert image to tensor\n",
        "    transforms.Normalize(mean=mean, std=std)  # Normalize with mean and std\n",
        "])\n",
        "\n",
        "# No augmentation for test set (only normalization)\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)  # Normalize with mean and std\n",
        "])\n",
        "\n",
        "# Load training and testing datasets\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define labels\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'lorry')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "ejYbu1lREwwA"
      },
      "outputs": [],
      "source": [
        "# # From the PyTorch's tutorial on image classification\n",
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "\n",
        "# def imshow(img):\n",
        "#     '''\n",
        "#     Show an image\n",
        "#     Input: image file to show\n",
        "#     Output: image\n",
        "#     '''\n",
        "#     img = img / 2 + 0.5     # unnormalize\n",
        "#     npimg = img.numpy()\n",
        "#     plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "#     plt.show()\n",
        "\n",
        "# # Get random training images\n",
        "# dataiter = iter(trainloader)\n",
        "# images, labels = next(dataiter)\n",
        "\n",
        "# # Show images\n",
        "# imshow(torchvision.utils.make_grid(images))\n",
        "# # Print labels\n",
        "# print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28nn7m9c_1AK"
      },
      "source": [
        "# Main model\n",
        "Divided as such:\n",
        "\n",
        "\n",
        "*   **Stem**: takes the images as inputs, extracts features from them\n",
        "*   **Backbone**: made up of *K* branches, made up of an expert branch\n",
        "*   **Classifier**: takes input from the last block\n",
        "*   **Model**: wraps all together\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjsIHiWpC7ir"
      },
      "source": [
        "## Stem\n",
        "*   Takes images as inputs\n",
        "*   Extracts a feature representation from them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "GPmPcMg3MKuo"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class Stem(nn.Module):\n",
        "  '''\n",
        "  Extract features using a Resnet-18 stem\n",
        "  Reference: Week 09 Lab\n",
        "  '''\n",
        "  def __init__(self, input_channels, middle_channels, output_channels):\n",
        "     super(Stem,self).__init__()\n",
        "     # Default parameters\n",
        "     kernel_size=3\n",
        "     stride=1\n",
        "     padding=1\n",
        "     \n",
        "     # Combine multiple layers\n",
        "     self.stem = nn.Sequential(\n",
        "       nn.Conv2d(input_channels, middle_channels, kernel_size = kernel_size, stride = stride, padding = padding),\n",
        "       nn.BatchNorm2d(middle_channels), \n",
        "       nn.ReLU(inplace=True),\n",
        "       nn.Conv2d(middle_channels, middle_channels,kernel_size = kernel_size, stride = stride, padding = padding),\n",
        "       nn.BatchNorm2d(middle_channels),\n",
        "       nn.ReLU(inplace=True),\n",
        "       nn.MaxPool2d(2), # Half the size of the image\n",
        "       nn.Conv2d(middle_channels, output_channels, kernel_size = kernel_size, stride = stride, padding = padding),\n",
        "       nn.BatchNorm2d(output_channels),\n",
        "       nn.ReLU(inplace=True),\n",
        "       nn.MaxPool2d(2) # Half the size of the image\n",
        "       )\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.stem(x)\n",
        "    # print(\"Stem output shape in forward pass:\", x.shape)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teldaHE3NAuT"
      },
      "source": [
        "## Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "q50v5kSs9Lbc"
      },
      "outputs": [],
      "source": [
        "class ExpertBranch(nn.Module):\n",
        "  '''\n",
        "  Expert branch predicting vector a with K elements from input tensor X\n",
        "  '''\n",
        "  def __init__(self, input_channels, k, r):\n",
        "    super(ExpertBranch,self).__init__()\n",
        "    # Spatially pool x\n",
        "    self.pool= nn.AdaptiveAvgPool2d(1)\n",
        "    #Forward through fc1, reducing by r\n",
        "    self.fc1= nn.Linear(input_channels, input_channels//r)\n",
        "    # Activation function ReLu\n",
        "    self.relu= nn.ReLU()\n",
        "    # Forward through fc2\n",
        "    self.fc2= nn.Linear(input_channels//r,k)\n",
        "\n",
        "  def forward(self,x):\n",
        "    # Spatially pool X\n",
        "    x = self.pool(x)\n",
        "    # Forward through fc1, reducing by r\n",
        "    x= x.squeeze(-1).squeeze(-1)\n",
        "    x = self.fc1(x)\n",
        "    # Processed through non-linear activation g\n",
        "    x = F.relu(x)\n",
        "    # Pass through fc2\n",
        "    x = self.fc2(x)\n",
        "    # Forward with softmax\n",
        "    x = F.softmax(x,dim=1)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "xUNibZ2FNE3V"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "  '''\n",
        "  Block\n",
        "  '''\n",
        "  def __init__(self, input_channels, output_channels, k, r):\n",
        "    super(Block, self).__init__()\n",
        "    # Default parameters\n",
        "    kernel_size=3\n",
        "    stride=1\n",
        "    padding=1\n",
        "    # Set parameters\n",
        "    self.k= k\n",
        "    self.expertBranch = ExpertBranch(input_channels, k=k, r=r)\n",
        "    # Input from first block\n",
        "    # Input from previous block for rest\n",
        "    # Generate vector a with K elements from X as a= E(X)\n",
        "    # Create K convolutional layers\n",
        "    self.convs= nn.ModuleList([\n",
        "        nn.Conv2d(input_channels, output_channels, kernel_size=kernel_size, stride= stride, padding=padding)\n",
        "        for _ in range(k)\n",
        "    ])\n",
        "\n",
        "  def forward(self,x):\n",
        "    identity= x\n",
        "    # Vector a from expert branch\n",
        "    a = self.expertBranch(x)\n",
        "    # Convolutional layers \n",
        "    conv_outputs = [conv(x) for conv in self.convs]\n",
        "    stacked = torch.stack(conv_outputs, dim=1)\n",
        "    # Create vector O\n",
        "    a= a.view(a.size(0), self.k, 1,1,1)\n",
        "\n",
        "    out = (a* stacked).sum(dim=1)\n",
        "    # Skip connection to stablise gradient descent\n",
        "    out += identity\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NatobdwZM-dN"
      },
      "source": [
        "## Backbone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "2uZ7am7LOxUi"
      },
      "outputs": [],
      "source": [
        "class Backbone(nn.Module):\n",
        "  '''\n",
        "  N blocks\n",
        "  '''\n",
        "  def __init__(self, input_channels, hidden_channels, num_blocks, k, r):\n",
        "    super(Backbone, self).__init__()\n",
        "    self.blocks= nn.ModuleList()\n",
        "\n",
        "    # First block takes input from stem\n",
        "    self.blocks.append(Block(input_channels, hidden_channels, k=k, r=r))\n",
        "\n",
        "    # Rest of blocks take input form previous block\n",
        "    for _ in range(1, num_blocks):\n",
        "      self.blocks.append(Block(hidden_channels, hidden_channels, k=k, r=r))\n",
        "\n",
        "  def forward(self, x):\n",
        "    for idx, block in enumerate(self.blocks):\n",
        "      x = block(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zgi2QD7KNC9v"
      },
      "source": [
        "## Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "t8QmbjyB4feJ"
      },
      "outputs": [],
      "source": [
        "class Classifier(nn.Module):\n",
        "  def __init__(self, input_channels, num_classes, use_mlp):\n",
        "    super(Classifier,self).__init__()\n",
        "    # Default parameters\n",
        "    dropout_rate=0.5\n",
        "    # Spatially pool\n",
        "    self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "    self.use_mlp= use_mlp\n",
        "\n",
        "    if use_mlp:\n",
        "      self.classifier= nn.Sequential(\n",
        "          nn.Linear(input_channels, input_channels*2),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(dropout_rate), # Deeper network with 3 layers\n",
        "          nn.Linear(input_channels*2, input_channels),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(dropout_rate),\n",
        "          nn.Linear(input_channels, num_classes)\n",
        "      )\n",
        "    else:\n",
        "      self.classifier= nn.Linear(input_channels, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(x).squeeze(-1).squeeze(-1)\n",
        "    out = self.classifier(x)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySRxujey4gN3"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "YY9DBSBo4jpP"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, input_channels, stem_channels, middle_channels, hidden_channels, num_blocks, k, r, num_classes, use_mlp):\n",
        "    super(Model, self).__init__()\n",
        "    # Call stem\n",
        "    self.stem= Stem(\n",
        "      input_channels=input_channels,\n",
        "      middle_channels=middle_channels,\n",
        "      output_channels=stem_channels\n",
        "    )\n",
        "    # Call backbone\n",
        "    self.backbone= Backbone(\n",
        "      input_channels=stem_channels, \n",
        "      hidden_channels= hidden_channels, \n",
        "      num_blocks=num_blocks,\n",
        "      k=k, \n",
        "      r=r)\n",
        "    # Call classifier\n",
        "    self.classifier= Classifier(\n",
        "      input_channels=hidden_channels, \n",
        "      num_classes=num_classes,\n",
        "      use_mlp= use_mlp)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x= self.stem(x)\n",
        "    x= self.backbone(x)\n",
        "    x= self.classifier(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tC2qAy2b_3KO"
      },
      "source": [
        "# Create the loss and optmiser\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGJbtSC3EcHy"
      },
      "outputs": [],
      "source": [
        "model = Model(\n",
        "    input_channels=3,\n",
        "    stem_channels=128,\n",
        "    middle_channels=64,\n",
        "    hidden_channels=128,\n",
        "    num_blocks=7,\n",
        "    k=4,\n",
        "    r=4,\n",
        "    num_classes=10,\n",
        "    use_mlp=True\n",
        ")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlNFWcuJ_8dY"
      },
      "source": [
        "# Training & Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdK9bHyHRaVt",
        "outputId": "f59cac49-555d-4148-9435-d29fb3076c79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/782 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.9869 | Accuracy: 21.63%\n",
            "Val   Loss: 1.7253 | Accuracy: 28.82%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 2/25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 135.5030 | Accuracy: 24.00%\n",
            "Val   Loss: 2.3032 | Accuracy: 10.00%\n",
            "\n",
            "Epoch 3/25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 94.0607 | Accuracy: 9.85%\n",
            "Val   Loss: 2.3026 | Accuracy: 10.00%\n",
            "\n",
            "Epoch 4/25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                           \r"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[140], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 59\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     val_loss, val_acc \u001b[38;5;241m=\u001b[39m evaluate(model, testloader, criterion, device)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# Log metrics\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[140], line 23\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, loader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     20\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 23\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     26\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[138], line 24\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[0;32m---> 24\u001b[0m   x\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m   x\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone(x)\n\u001b[1;32m     26\u001b[0m   x\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(x)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[133], line 31\u001b[0m, in \u001b[0;36mStem.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[0;32m---> 31\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m   \u001b[38;5;66;03m# print(\"Stem output shape in forward pass:\", x.shape)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:151\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches_tracked \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_batches_tracked\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# use cumulative moving average\u001b[39;00m\n\u001b[1;32m    153\u001b[0m             exponential_average_factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches_tracked)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Set up device \n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Save model\n",
        "model.to(device)\n",
        "\n",
        "# Log training \n",
        "train_losses, val_losses = [], []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "# Training and Validation Loops \n",
        "def train(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    return running_loss / len(loader), 100 * correct / total\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    return loss / len(loader), 100 * correct / total\n",
        "\n",
        "# Main Loop \n",
        "epochs = 25\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "    train_loss, train_acc = train(model, trainloader, criterion, optimizer, device)\n",
        "    val_loss, val_acc = evaluate(model, testloader, criterion, device)\n",
        "\n",
        "\n",
        "    # Log metrics\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    val_accuracies.append(val_acc)\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Accuracy: {train_acc:.2f}%\")\n",
        "    print(f\"Val   Loss: {val_loss:.4f} | Accuracy: {val_acc:.2f}%\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "        print(\"Saved best model.\")\n",
        "\n",
        "print(\"\\nTraining Complete\")\n",
        "\n",
        "# Print Final Averages \n",
        "avg_train_loss = sum(train_losses) / len(train_losses)\n",
        "avg_val_loss = sum(val_losses) / len(val_losses)\n",
        "avg_train_acc = sum(train_accuracies) / len(train_accuracies)\n",
        "avg_val_acc = sum(val_accuracies) / len(val_accuracies)\n",
        "\n",
        "print(\"\\nFinal Averages Over All Epochs\")\n",
        "print(f\"Average Train Loss: {avg_train_loss:.4f}\")\n",
        "print(f\"Average Train Accuracy: {avg_train_acc:.2f}%\")\n",
        "print(f\"Average Val   Loss: {avg_val_loss:.4f}\")\n",
        "print(f\"Average Val   Accuracy: {avg_val_acc:.2f}%\")\n",
        "\n",
        "\n",
        "# Plot results\n",
        "\n",
        "# Plot Loss\n",
        "plt.figure()\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.title(\"Loss Curve\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.savefig(\"loss_curve.png\")\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.figure()\n",
        "plt.plot(train_accuracies, label='Train Accuracy')\n",
        "plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "plt.title(\"Accuracy Curve\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.savefig(\"accuracy_curve.png\")\n",
        "\n",
        "print(\"Plots saved: loss_curve.png and accuracy_curve.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ### Data loading and augmentation from test_train.py ###\n",
        "# # Added Normalize with the standard CIFAR-10 statistics\n",
        "# transform_train = transforms.Compose([\n",
        "#     transforms.RandomCrop(32, padding=4),\n",
        "#     transforms.RandomHorizontalFlip(),\n",
        "#     transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616])\n",
        "# ])\n",
        "# transform_test = transforms.Compose([\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616])\n",
        "# ])\n",
        "\n",
        "# # Downloading and creating the Datasets here\n",
        "# train_dataset = torchvision.datasets.CIFAR10(\n",
        "#     root='./data', train=True, download=True, transform=transform_train\n",
        "# )\n",
        "# test_dataset = torchvision.datasets.CIFAR10(\n",
        "#     root='./data', train=False, download=True, transform=transform_test\n",
        "# )\n",
        "\n",
        "# # Creating DataLoaders here\n",
        "# batch_size = 128\n",
        "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "# ### Training utilities from test_train.py (with fixed method names) ###\n",
        "# class Accumulator:\n",
        "#     \"\"\"For accumulating sums over n variables.\"\"\"\n",
        "#     def __init__(self, n):\n",
        "#         self.data = [0.0] * n\n",
        "#     def add(self, *args):\n",
        "#         self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
        "#     def reset(self):\n",
        "#         self.data = [0.0] * len(self.data)\n",
        "#     def __getitem__(self, idx):\n",
        "#         return self.data[idx]\n",
        "\n",
        "# def accuracy(y_hat, y):\n",
        "#     \"\"\"Compute the number of correct predictions.\"\"\"\n",
        "#     if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
        "#         y_hat = y_hat.argmax(axis=1)\n",
        "#     cmp = (y_hat.type(y.dtype) == y)\n",
        "#     return float(torch.sum(cmp))\n",
        "\n",
        "# def evaluate_accuracy(net, data_iter, device): \n",
        "#     \"\"\"Compute the accuracy for a model on a dataset.\"\"\"\n",
        "#     net.eval()\n",
        "#     metric = Accumulator(2)  # No. of correct predictions, no. of predictions\n",
        "#     with torch.no_grad():\n",
        "#         for X, y in data_iter:\n",
        "#             X, y = X.to(device), y.to(device)\n",
        "#             metric.add(accuracy(net(X), y), y.numel())\n",
        "#     return metric[0] / metric[1]\n",
        "\n",
        "# def train_epoch(net, train_iter, loss, optimizer, device):\n",
        "#     \"\"\"Training function for one epoch.\"\"\"\n",
        "#     net.train()\n",
        "#     metric = Accumulator(3)  # train_loss, train_acc, num_examples\n",
        "#     for X, y in train_iter:\n",
        "#         X, y = X.to(device), y.to(device)\n",
        "#         optimizer.zero_grad()\n",
        "#         y_hat = net(X)\n",
        "#         l = loss(y_hat, y)\n",
        "#         l.backward()\n",
        "#         optimizer.step()\n",
        "#         metric.add(float(l) * len(y), accuracy(y_hat, y), y.numel())\n",
        "#     return metric[0] / metric[2], metric[1] / metric[2]\n",
        "\n",
        "# def train_model(net, train_iter, test_iter, loss, optimizer, num_epochs, device):\n",
        "#     \"\"\"Train and evaluate a model.\"\"\"\n",
        "#     print('-' * 50)\n",
        "#     print('Starting training...')\n",
        "    \n",
        "#     train_losses = []\n",
        "#     train_accs = []\n",
        "#     test_accs = []\n",
        "    \n",
        "#     for epoch in range(num_epochs):\n",
        "#         train_metrics = train_epoch(net, train_iter, loss, optimizer, device)\n",
        "#         test_acc = evaluate_accuracy(net, test_iter, device)\n",
        "#         train_loss, train_acc = train_metrics\n",
        "        \n",
        "#         train_losses.append(train_loss)\n",
        "#         train_accs.append(train_acc)\n",
        "#         test_accs.append(test_acc)\n",
        "        \n",
        "#         print(f'Epoch {epoch + 1}:')\n",
        "#         print(f'  Train loss: {train_loss:.3f}')\n",
        "#         print(f'  Train accuracy: {train_acc:.3f} ({train_acc*100:.1f}%)')\n",
        "#         print(f'  Test accuracy:  {test_acc:.3f} ({test_acc*100:.1f}%)')\n",
        "    \n",
        "#     # Plot metrics\n",
        "#     plt.figure(figsize=(12, 4))\n",
        "#     plt.subplot(1, 2, 1)\n",
        "#     plt.plot(train_losses, label='train loss')\n",
        "#     plt.xlabel('epoch')\n",
        "#     plt.ylabel('loss')\n",
        "#     plt.legend()\n",
        "    \n",
        "#     plt.subplot(1, 2, 2)\n",
        "#     plt.plot([x*100 for x in train_accs], label='train acc (%)')\n",
        "#     plt.plot([x*100 for x in test_accs], label='test acc (%)')\n",
        "#     plt.xlabel('epoch')\n",
        "#     plt.ylabel('accuracy (%)')\n",
        "#     plt.legend()\n",
        "#     plt.savefig('training_results.png')\n",
        "#     plt.show()\n",
        "    \n",
        "#     return train_losses, train_accs, test_accs\n",
        "\n",
        "# ### Main execution block ###\n",
        "# if __name__ == '__main__':\n",
        "#     # Device configuration\n",
        "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#     if device.type == 'cuda':\n",
        "#         print('GPU training enabled')  # Simplified device info\n",
        "    \n",
        "#     # Create your model from mymodel.py\n",
        "#     model = Model(\n",
        "#         stem_channels=128,\n",
        "#         hidden_channels=128,\n",
        "#         num_blocks=3,\n",
        "#         k=4,\n",
        "#         r=4,\n",
        "#         num_classes=10,\n",
        "#         use_mlp=True\n",
        "#     ).to(device)\n",
        "    \n",
        "#     # Define loss function and optimizer\n",
        "#     criterion = nn.CrossEntropyLoss()\n",
        "#     optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    \n",
        "#     # Train the model\n",
        "#     train_losses, train_accs, test_accs = train_model(\n",
        "#         model, train_loader, test_loader, criterion, optimizer, num_epochs=25, device=device\n",
        "#     )\n",
        "    \n",
        "#     # Save model\n",
        "#     torch.save(model.state_dict(), \"best_model.pth\")\n",
        "#     print(\"Model saved as best_model.pth\")\n",
        "    \n",
        "#     # Print final metrics\n",
        "#     print(\"\\nFinal Metrics:\")\n",
        "#     print(f\"Final train loss: {train_losses[-1]:.4f}\")\n",
        "#     print(f\"Final train accuracy: {train_accs[-1]*100:.2f}%\")\n",
        "#     print(f\"Final test accuracy: {test_accs[-1]*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnF3CN1zohxI"
      },
      "source": [
        "Averages:\n",
        "\n",
        "\n",
        "*   Train Loss: 1.7223, Accuracy: 38.21%, Validation Loss: 1.7194, Accuracy: 38.25%\n",
        "*   Train Loss: 1.7106, Accuracy: 34.80%, Validation Loss: 1.7984, Accuracy: 35.98%\n",
        "\n",
        "*   Train Loss: 1.8150, Accuracy: 34.54%, Val   Loss: 1.7848 Accuracy: 36.13%\n",
        "\n",
        "*   Train Loss: 1.9579, Accuracy: 28.84%, Val   Loss: 1.8691, Accuracy: 32.51%\n",
        "*   Train Loss: 1.9712, Accuracy: 27.54%, Val   Loss: 1.9107 ,Accuracy: 30.24%\n",
        "*   Train Loss: 2.1609, Accuracy: 16.97%, Val   Loss: 2.1343, Accuracy: 18.28%\n",
        "*   Train Loss: 1.9798, Accuracy: 27.24%, Val   Loss: 1.9312, Accuracy: 29.65%\n",
        "*   Train Loss: 1.4970, Accuracy: 44.11%, Val   Loss: 1.3675, Accuracy: 48.65%\n",
        "*   Train Loss: 1.3648, Accuracy: 51.66%, Val   Loss: 1.2319, Val   Accuracy: 55.56%\n",
        "*   Train Loss: 0.7390, Accuracy: 74.50%, Val   Loss: 0.8193, Val   Accuracy: 72.47%\n",
        "*  Train Loss: 0.7262, Accuracy: 74.99%, Val   Loss: 0.8539, Accuracy: 71.57%\n",
        "*   Train Loss: 0.6575, Accuracy: 76.88%, Val   Loss: 0.7876, Accuracy: 73.31%\n",
        "*   Train Loss: 0.6564, Accuracy: 76.91%, Val   Loss: 0.7731, Accuracy: 73.89%\n",
        "*   Train Loss: 0.6747, Accuracy: 76.24%, Val   Loss: 0.7645, Accuracy: 73.83%\n",
        "*   Train Loss: 0.7119, Accuracy: 74.75%, Val   Loss: 0.8092, Accuracy: 72.01%\n",
        "* Train Loss: 1.0820, Accuracy: 61.24%,  Val   Loss: 0.9241, Accuracy: 66.86%\n",
        "* Train Accuracy: 62.14%, Val   Loss: 0.8826, Accuracy: 68.16%"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
