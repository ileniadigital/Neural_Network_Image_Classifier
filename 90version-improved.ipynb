{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-ugYIZG_vwU"
      },
      "source": [
        "# Read dataset and create data loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sUdX_1lQ7Zf8"
      },
      "outputs": [],
      "source": [
        "# Import torch and CIFAR dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Import matplotlib and numpy for graphs\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Dy0dXGIAAs-N"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Import CIFAR dataset, define labbels and load training and validation dataset\n",
        "Reference for loading dataset: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
        "Reference for augmentation: https://pytorch.org/vision/stable/transforms.html\n",
        "'''\n",
        "# Define batch size\n",
        "batch_size = 128\n",
        "\n",
        "# Normalisation and std values for RGB in dataset\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "# Data augmentation for training set\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),  # Randomly crop the image with padding\n",
        "    transforms.RandomHorizontalFlip(),    # Randomly flip the image horizontally\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Adjust brightness, contrast, etc.\n",
        "    transforms.RandomRotation(15),        # Randomly rotate the image by up to 15 degrees\n",
        "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1)),  # Randomly translate the image\n",
        "    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
        "    transforms.AutoAugment(transforms.AutoAugmentPolicy.CIFAR10),\n",
        "    transforms.ToTensor(),                # Convert image to tensor\n",
        "    transforms.Normalize(mean=mean, std=std),  # Normalize with mean and std\n",
        "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.33))  # Randomly erase a portion of the image (optional)\n",
        "])\n",
        "\n",
        "# No augmentation for test set (only normalization)\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)  # Normalize with mean and std\n",
        "])\n",
        "\n",
        "# Load training and testing datasets\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define labels\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'lorry')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ejYbu1lREwwA"
      },
      "outputs": [],
      "source": [
        "# # From the PyTorch's tutorial on image classification\n",
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "\n",
        "# def imshow(img):\n",
        "#     '''\n",
        "#     Show an image\n",
        "#     Input: image file to show\n",
        "#     Output: image\n",
        "#     '''\n",
        "#     img = img / 2 + 0.5     # unnormalize\n",
        "#     npimg = img.numpy()\n",
        "#     plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "#     plt.show()\n",
        "\n",
        "# # Get random training images\n",
        "# dataiter = iter(trainloader)\n",
        "# images, labels = next(dataiter)\n",
        "\n",
        "# # Show images\n",
        "# imshow(torchvision.utils.make_grid(images))\n",
        "# # Print labels\n",
        "# print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28nn7m9c_1AK"
      },
      "source": [
        "# Main model\n",
        "Divided as such:\n",
        "\n",
        "\n",
        "*   **Stem**: takes the images as inputs, extracts features from them\n",
        "*   **Backbone**: made up of *K* branches, made up of an expert branch\n",
        "*   **Classifier**: takes input from the last block\n",
        "*   **Model**: wraps all together\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjsIHiWpC7ir"
      },
      "source": [
        "## Stem\n",
        "*   Takes images as inputs\n",
        "*   Extracts a feature representation from them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GPmPcMg3MKuo"
      },
      "outputs": [],
      "source": [
        "class Stem(nn.Module):\n",
        "  '''\n",
        "  Extract features using a Resnet-18 stem\n",
        "  Reference: Week 09 Lab\n",
        "  '''\n",
        "  def __init__(self, input_channels, middle_channels, output_channels):\n",
        "     super(Stem,self).__init__()\n",
        "     # Default parameters\n",
        "     kernel_size=3\n",
        "     stride=1\n",
        "     padding=1\n",
        "     \n",
        "     # Combine multiple layers\n",
        "     self.stem = nn.Sequential(\n",
        "       nn.Conv2d(input_channels, middle_channels, kernel_size = kernel_size, stride = stride, padding = padding),\n",
        "       nn.BatchNorm2d(middle_channels), \n",
        "       nn.ReLU(inplace=True),\n",
        "       nn.Conv2d(middle_channels, middle_channels,kernel_size = kernel_size, stride = stride, padding = padding),\n",
        "       nn.BatchNorm2d(middle_channels),\n",
        "       nn.ReLU(inplace=True),\n",
        "       nn.MaxPool2d(2), # Half the size of the image\n",
        "       nn.Conv2d(middle_channels, output_channels, kernel_size = kernel_size, stride = stride, padding = padding),\n",
        "       nn.BatchNorm2d(output_channels),\n",
        "       nn.ReLU(inplace=True),\n",
        "       nn.MaxPool2d(2) # Half the size of the image\n",
        "       )\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.stem(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teldaHE3NAuT"
      },
      "source": [
        "## Expert Branch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "q50v5kSs9Lbc"
      },
      "outputs": [],
      "source": [
        "class ExpertBranch(nn.Module):\n",
        "  '''\n",
        "  Expert branch predicting vector a with K elements from input tensor X\n",
        "  '''\n",
        "  def __init__(self, input_channels, k, r):\n",
        "    super(ExpertBranch,self).__init__()\n",
        "    # Spatially pool x\n",
        "    self.pool= nn.AdaptiveAvgPool2d(1)\n",
        "    #Forward through fc1, reducing by r\n",
        "    self.fc1= nn.Linear(input_channels, input_channels//r)\n",
        "    # Activation function ReLu\n",
        "    self.relu= nn.ReLU()\n",
        "    # Forward through fc2\n",
        "    self.fc2= nn.Linear(input_channels//r,k)\n",
        "\n",
        "  def forward(self,x):\n",
        "    # Spatially pool X\n",
        "    x = self.pool(x)\n",
        "    # Forward through fc1, reducing by r\n",
        "    x= x.squeeze(-1).squeeze(-1)\n",
        "    x = self.fc1(x)\n",
        "    # Processed through non-linear activation g\n",
        "    x = F.relu(x)\n",
        "    # Pass through fc2\n",
        "    x = self.fc2(x)\n",
        "    # Forward with softmax\n",
        "    x = F.softmax(x,dim=1)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xUNibZ2FNE3V"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "  '''\n",
        "  Block\n",
        "  '''\n",
        "  def __init__(self, input_channels, output_channels, k, r):\n",
        "    super(Block, self).__init__()\n",
        "\n",
        "    # Default parameters\n",
        "    kernel_size=3\n",
        "    stride=1\n",
        "    padding=1\n",
        "\n",
        "    # Set parameters\n",
        "    self.k= k\n",
        "    self.expertBranch = ExpertBranch(input_channels, k=k, r=r)\n",
        "\n",
        "    # Create K convolutional layers\n",
        "    self.convs= nn.ModuleList([\n",
        "        nn.Conv2d(input_channels, output_channels, kernel_size=kernel_size, stride= stride, padding=padding)\n",
        "        for _ in range(k)\n",
        "    ])\n",
        "\n",
        "    # If dimensions do not match\n",
        "    self.downsample = None\n",
        "    if input_channels != output_channels:\n",
        "        self.downsample = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, output_channels, kernel_size=1, stride=1, bias=False),\n",
        "            nn.BatchNorm2d(output_channels)\n",
        "        )\n",
        "\n",
        "  def forward(self,x):\n",
        "    identity= x\n",
        "    # Vector a from expert branch\n",
        "    a = self.expertBranch(x)\n",
        "    # Convolutional layers \n",
        "    conv_outputs = [conv(x) for conv in self.convs]\n",
        "    stacked = torch.stack(conv_outputs, dim=1)\n",
        "\n",
        "    # Create vector O\n",
        "    a= a.view(a.size(0), self.k, 1,1,1)\n",
        "    out = (a* stacked).sum(dim=1)\n",
        "\n",
        "    # Apply downsampling for mismatched dimensions\n",
        "    if self.downsample is not None:\n",
        "        identity = self.downsample(identity)\n",
        "        \n",
        "    # Skip connection to stablise gradient descent\n",
        "    out += identity\n",
        "    out = F.relu(out) # activation after skip\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NatobdwZM-dN"
      },
      "source": [
        "## Backbone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "2uZ7am7LOxUi"
      },
      "outputs": [],
      "source": [
        "class Backbone(nn.Module):\n",
        "  '''\n",
        "  N blocks\n",
        "  '''\n",
        "  def __init__(self, input_channels, hidden_channels, num_blocks, k, r):\n",
        "    super(Backbone, self).__init__()\n",
        "    self.blocks= nn.ModuleList()\n",
        "\n",
        "    # First block takes input from stem\n",
        "    self.blocks.append(Block(input_channels, hidden_channels, k=k, r=r))\n",
        "\n",
        "    # Rest of blocks take input form previous block\n",
        "    for _ in range(1, num_blocks):\n",
        "      self.blocks.append(Block(hidden_channels, hidden_channels, k=k, r=r))\n",
        "\n",
        "  def forward(self, x):\n",
        "    for idx, block in enumerate(self.blocks):\n",
        "      x = block(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zgi2QD7KNC9v"
      },
      "source": [
        "## Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "t8QmbjyB4feJ"
      },
      "outputs": [],
      "source": [
        "class Classifier(nn.Module):\n",
        "  def __init__(self, input_channels, num_classes, use_mlp):\n",
        "    super(Classifier,self).__init__()\n",
        "    # Default parameters\n",
        "    dropout_rate=0.45\n",
        "    # Spatially pool\n",
        "    self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "    self.use_mlp= use_mlp\n",
        "\n",
        "    if use_mlp:\n",
        "      self.classifier= nn.Sequential(\n",
        "          nn.Linear(input_channels, input_channels*2),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(dropout_rate), # Deeper network with 3 layers\n",
        "          nn.Linear(input_channels*2, input_channels),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(dropout_rate),\n",
        "          nn.Linear(input_channels, num_classes)\n",
        "      )\n",
        "    else:\n",
        "      self.classifier= nn.Linear(input_channels, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(x).squeeze(-1).squeeze(-1)\n",
        "    out = self.classifier(x)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySRxujey4gN3"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "YY9DBSBo4jpP"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, input_channels, output_channels, middle_channels, hidden_channels, num_blocks, k, r, num_classes, use_mlp):\n",
        "    super(Model, self).__init__()\n",
        "    # Call stem\n",
        "    self.stem= Stem(\n",
        "      input_channels=input_channels,\n",
        "      middle_channels=middle_channels,\n",
        "      output_channels=output_channels\n",
        "    )\n",
        "    # Call backbone\n",
        "    self.backbone= Backbone(\n",
        "      input_channels=output_channels, \n",
        "      hidden_channels= hidden_channels, \n",
        "      num_blocks=num_blocks,\n",
        "      k=k, \n",
        "      r=r)\n",
        "    # Call classifier\n",
        "    self.classifier= Classifier(\n",
        "      input_channels=hidden_channels, \n",
        "      num_classes=num_classes,\n",
        "      use_mlp= use_mlp)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x= self.stem(x)\n",
        "    x= self.backbone(x)\n",
        "    x= self.classifier(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tC2qAy2b_3KO"
      },
      "source": [
        "# Create the loss and optmiser\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGJbtSC3EcHy"
      },
      "outputs": [],
      "source": [
        "model = Model(\n",
        "    input_channels=3,\n",
        "    output_channels=128,\n",
        "    middle_channels=64,\n",
        "    hidden_channels=512,\n",
        "    num_blocks=7,\n",
        "    k=8,\n",
        "    r=4,\n",
        "    num_classes=10,\n",
        "    use_mlp=True\n",
        ")\n",
        "\n",
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "    elif isinstance(m, nn.BatchNorm2d):\n",
        "        nn.init.constant_(m.weight, 1)\n",
        "        nn.init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):\n",
        "        nn.init.kaiming_normal_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.07, weight_decay=4e-4, momentum=0.9, nesterov=True)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
        "\n",
        "warmup_scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.1, total_iters=8)\n",
        "main_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=300)\n",
        "scheduler = torch.optim.lr_scheduler.SequentialLR(\n",
        "    optimizer, \n",
        "    schedulers=[warmup_scheduler, main_scheduler],\n",
        "    milestones=[5]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlNFWcuJ_8dY"
      },
      "source": [
        "# Training & Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdK9bHyHRaVt",
        "outputId": "f59cac49-555d-4148-9435-d29fb3076c79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size: 128\n",
            "\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: nan | Accuracy: 10.00%\n",
            "Val   Loss: nan | Accuracy: 10.00%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 2/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: nan | Accuracy: 10.00%\n",
            "Val   Loss: nan | Accuracy: 10.00%\n",
            "No improvement for 1 epochs.\n",
            "\n",
            "Epoch 3/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                         \r"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[22], line 64\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 64\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     val_loss, val_acc \u001b[38;5;241m=\u001b[39m evaluate(model, testloader, criterion, device)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# Log metrics\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[22], line 32\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, loader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     29\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     30\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 32\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     34\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Set up device \n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Save model\n",
        "model.to(device)\n",
        "\n",
        "# Log training \n",
        "train_losses, val_losses = [], []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "batch_size=128\n",
        "print('Batch size:', batch_size)\n",
        "\n",
        "# Training and Validation Loops \n",
        "def train(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    return running_loss / len(loader), 100 * correct / total\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    return loss / len(loader), 100 * correct / total\n",
        "\n",
        "# Main Loop \n",
        "patience = 20 # Number of epochs to wait for improvement\n",
        "early_stop_counter = 0 # Counter for early stopping\n",
        "epochs = 200\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "    train_loss, train_acc = train(model, trainloader, criterion, optimizer, device)\n",
        "    val_loss, val_acc = evaluate(model, testloader, criterion, device)\n",
        "\n",
        "\n",
        "    # Log metrics\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    val_accuracies.append(val_acc)\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Accuracy: {train_acc:.2f}%\")\n",
        "    print(f\"Val   Loss: {val_loss:.4f} | Accuracy: {val_acc:.2f}%\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        early_stop_counter=0\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "        print(\"Saved best model.\")\n",
        "    else:\n",
        "        early_stop_counter += 1\n",
        "        print(f\"No improvement for {early_stop_counter} epochs.\")\n",
        "\n",
        "    if early_stop_counter >= patience:\n",
        "        print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
        "        break\n",
        "print(\"\\nTraining Complete\")\n",
        "\n",
        "# Print Final Averages \n",
        "avg_train_loss = sum(train_losses) / len(train_losses)\n",
        "avg_val_loss = sum(val_losses) / len(val_losses)\n",
        "avg_train_acc = sum(train_accuracies) / len(train_accuracies)\n",
        "avg_val_acc = sum(val_accuracies) / len(val_accuracies)\n",
        "\n",
        "print(\"\\nFinal Averages Over All Epochs\")\n",
        "print(f\"Average Train Loss: {avg_train_loss:.4f}\")\n",
        "print(f\"Average Train Accuracy: {avg_train_acc:.2f}%\")\n",
        "print(f\"Average Val   Loss: {avg_val_loss:.4f}\")\n",
        "print(f\"Average Val   Accuracy: {avg_val_acc:.2f}%\")\n",
        "\n",
        "\n",
        "# Plot results\n",
        "\n",
        "# Plot Loss\n",
        "plt.figure()\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.title(\"Loss Curve\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.savefig(\"loss_curve.png\")\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.figure()\n",
        "plt.plot(train_accuracies, label='Train Accuracy')\n",
        "plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "plt.title(\"Accuracy Curve\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.savefig(\"accuracy_curve.png\")\n",
        "\n",
        "print(\"Plots saved: loss_curve.png and accuracy_curve.png\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
