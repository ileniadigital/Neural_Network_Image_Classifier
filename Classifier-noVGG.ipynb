{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-ugYIZG_vwU"
      },
      "source": [
        "# Read dataset and create data loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "sUdX_1lQ7Zf8"
      },
      "outputs": [],
      "source": [
        "# Import torch and CIFAR dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Import matplotlib and numpy for graphs\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "Dy0dXGIAAs-N"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size: 64\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Import CIFAR dataset, define labbels and load training and validation dataset\n",
        "Reference for loading dataset: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
        "Reference for augmentation: https://pytorch.org/vision/stable/transforms.html\n",
        "'''\n",
        "batch_size=64 \n",
        "print('Batch size:', batch_size)\n",
        "\n",
        "# Normalisation and std values for RGB in dataset\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "# Data augmentation for training set\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),  # Randomly crop the image with padding\n",
        "    transforms.RandomHorizontalFlip(),    # Randomly flip the image horizontally\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Adjust brightness, contrast, etc.\n",
        "    transforms.RandomRotation(15),        # Randomly rotate the image by up to 15 degrees\n",
        "    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1)),  # Randomly translate the image\n",
        "    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),  # Randomly apply perspective transformation\n",
        "    transforms.ToTensor(),                # Convert image to tensor\n",
        "    transforms.Normalize(mean=mean, std=std),  # Normalize with mean and std\n",
        "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.3))  # Randomly erase a portion of the image (optional)\n",
        "])\n",
        "\n",
        "# No augmentation for test set (only normalization)\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)  # Normalize with mean and std\n",
        "])\n",
        "\n",
        "# Load training and testing datasets\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define labels\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'lorry')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "ejYbu1lREwwA"
      },
      "outputs": [],
      "source": [
        "# # From the PyTorch's tutorial on image classification\n",
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "\n",
        "# def imshow(img):\n",
        "#     '''\n",
        "#     Show an image\n",
        "#     Input: image file to show\n",
        "#     Output: image\n",
        "#     '''\n",
        "#     img = img / 2 + 0.5     # unnormalize\n",
        "#     npimg = img.numpy()\n",
        "#     plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "#     plt.show()\n",
        "\n",
        "# # Get random training images\n",
        "# dataiter = iter(trainloader)\n",
        "# images, labels = next(dataiter)\n",
        "\n",
        "# # Show images\n",
        "# imshow(torchvision.utils.make_grid(images))\n",
        "# # Print labels\n",
        "# print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28nn7m9c_1AK"
      },
      "source": [
        "# Main model\n",
        "Divided as such:\n",
        "\n",
        "\n",
        "*   **Stem**: takes the images as inputs, extracts features from them\n",
        "*   **Backbone**: made up of *K* branches, made up of an expert branch\n",
        "*   **Classifier**: takes input from the last block\n",
        "*   **Model**: wraps all together\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjsIHiWpC7ir"
      },
      "source": [
        "## Stem\n",
        "*   Takes images as inputs\n",
        "*   Extracts a feature representation from them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "GPmPcMg3MKuo"
      },
      "outputs": [],
      "source": [
        "class Stem(nn.Module):\n",
        "  '''\n",
        "  Extract features using a Resnet-18 stem\n",
        "  Reference: Week 09 Lab\n",
        "  '''\n",
        "  def __init__(self, input_channels, middle_channels, output_channels):\n",
        "     super(Stem,self).__init__()\n",
        "     # Default parameters\n",
        "     kernel_size=3\n",
        "     stride=1\n",
        "     padding=1\n",
        "     \n",
        "     # Combine multiple layers\n",
        "     self.stem = nn.Sequential(\n",
        "       nn.Conv2d(input_channels, middle_channels, kernel_size = kernel_size, stride = stride, padding = padding),\n",
        "       nn.BatchNorm2d(middle_channels), \n",
        "       nn.ReLU(inplace=True),\n",
        "       nn.Conv2d(middle_channels, middle_channels,kernel_size = kernel_size, stride = stride, padding = padding),\n",
        "       nn.BatchNorm2d(middle_channels),\n",
        "       nn.ReLU(inplace=True),\n",
        "       nn.MaxPool2d(2), # Half the size of the image\n",
        "       nn.Conv2d(middle_channels, output_channels, kernel_size = kernel_size, stride = stride, padding = padding),\n",
        "       nn.BatchNorm2d(output_channels),\n",
        "       nn.ReLU(inplace=True),\n",
        "       nn.MaxPool2d(2) # Half the size of the image\n",
        "       )\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.stem(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teldaHE3NAuT"
      },
      "source": [
        "## Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "q50v5kSs9Lbc"
      },
      "outputs": [],
      "source": [
        "class ExpertBranch(nn.Module):\n",
        "  '''\n",
        "  Expert branch predicting vector a with K elements from input tensor X\n",
        "  '''\n",
        "  def __init__(self, input_channels, k, r):\n",
        "    super(ExpertBranch,self).__init__()\n",
        "    # Spatially pool x\n",
        "    self.pool= nn.AdaptiveAvgPool2d(1)\n",
        "    #Forward through fc1, reducing by r\n",
        "    self.fc1= nn.Linear(input_channels, input_channels//r)\n",
        "    # Activation function ReLu\n",
        "    self.relu= nn.ReLU()\n",
        "    # Forward through fc2\n",
        "    self.fc2= nn.Linear(input_channels//r,k)\n",
        "\n",
        "  def forward(self,x):\n",
        "    # Spatially pool X\n",
        "    x = self.pool(x)\n",
        "    # Forward through fc1, reducing by r\n",
        "    x= x.squeeze(-1).squeeze(-1)\n",
        "    x = self.fc1(x)\n",
        "    # Processed through non-linear activation g\n",
        "    x = F.relu(x)\n",
        "    # Pass through fc2\n",
        "    x = self.fc2(x)\n",
        "    # Forward with softmax\n",
        "    x = F.softmax(x,dim=1)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "xUNibZ2FNE3V"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "  '''\n",
        "  Block\n",
        "  '''\n",
        "  def __init__(self, input_channels, output_channels, k, r):\n",
        "    super(Block, self).__init__()\n",
        "    # Default parameters\n",
        "    kernel_size=3\n",
        "    stride=1\n",
        "    padding=1\n",
        "    # Set parameters\n",
        "    self.k= k\n",
        "    self.expertBranch = ExpertBranch(input_channels, k=k, r=r)\n",
        "    # Input from first block\n",
        "    # Input from previous block for rest\n",
        "    # Generate vector a with K elements from X as a= E(X)\n",
        "    # Create K convolutional layers\n",
        "    self.convs= nn.ModuleList([\n",
        "        nn.Conv2d(input_channels, output_channels, kernel_size=kernel_size, stride= stride, padding=padding)\n",
        "        for _ in range(k)\n",
        "    ])\n",
        "\n",
        "  def forward(self,x):\n",
        "    identity= x\n",
        "    # Vector a from expert branch\n",
        "    a = self.expertBranch(x)\n",
        "    # Convolutional layers \n",
        "    conv_outputs = [conv(x) for conv in self.convs]\n",
        "    stacked = torch.stack(conv_outputs, dim=1)\n",
        "    # Create vector O\n",
        "    a= a.view(a.size(0), self.k, 1,1,1)\n",
        "\n",
        "    out = (a* stacked).sum(dim=1)\n",
        "    # Skip connection to stablise gradient descent\n",
        "    out += identity\n",
        "    out = F.relu(out) # activation after skip\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NatobdwZM-dN"
      },
      "source": [
        "## Backbone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "2uZ7am7LOxUi"
      },
      "outputs": [],
      "source": [
        "class Backbone(nn.Module):\n",
        "  '''\n",
        "  N blocks\n",
        "  '''\n",
        "  def __init__(self, input_channels, hidden_channels, num_blocks, k, r):\n",
        "    super(Backbone, self).__init__()\n",
        "    self.blocks= nn.ModuleList()\n",
        "\n",
        "    # First block takes input from stem\n",
        "    self.blocks.append(Block(input_channels, hidden_channels, k=k, r=r))\n",
        "\n",
        "    # Rest of blocks take input form previous block\n",
        "    for _ in range(1, num_blocks):\n",
        "      self.blocks.append(Block(hidden_channels, hidden_channels, k=k, r=r))\n",
        "\n",
        "  def forward(self, x):\n",
        "    for idx, block in enumerate(self.blocks):\n",
        "      x = block(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zgi2QD7KNC9v"
      },
      "source": [
        "## Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "t8QmbjyB4feJ"
      },
      "outputs": [],
      "source": [
        "class Classifier(nn.Module):\n",
        "  def __init__(self, input_channels, num_classes, use_mlp):\n",
        "    super(Classifier,self).__init__()\n",
        "    # Default parameters\n",
        "    dropout_rate=0.4\n",
        "    # Spatially pool\n",
        "    self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "    self.use_mlp= use_mlp\n",
        "\n",
        "    if use_mlp:\n",
        "      self.classifier= nn.Sequential(\n",
        "          nn.Linear(input_channels, input_channels*2),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(dropout_rate), # Deeper network with 3 layers\n",
        "          nn.Linear(input_channels*2, input_channels),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(dropout_rate),\n",
        "          nn.Linear(input_channels, num_classes)\n",
        "      )\n",
        "    else:\n",
        "      self.classifier= nn.Linear(input_channels, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(x).squeeze(-1).squeeze(-1)\n",
        "    out = self.classifier(x)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySRxujey4gN3"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "YY9DBSBo4jpP"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, input_channels, output_channels, middle_channels, hidden_channels, num_blocks, k, r, num_classes, use_mlp):\n",
        "    super(Model, self).__init__()\n",
        "    # Call stem\n",
        "    self.stem= Stem(\n",
        "      input_channels=input_channels,\n",
        "      middle_channels=middle_channels,\n",
        "      output_channels=output_channels\n",
        "    )\n",
        "    # Call backbone\n",
        "    self.backbone= Backbone(\n",
        "      input_channels=output_channels, \n",
        "      hidden_channels= hidden_channels, \n",
        "      num_blocks=num_blocks,\n",
        "      k=k, \n",
        "      r=r)\n",
        "    # Call classifier\n",
        "    self.classifier= Classifier(\n",
        "      input_channels=hidden_channels, \n",
        "      num_classes=num_classes,\n",
        "      use_mlp= use_mlp)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x= self.stem(x)\n",
        "    x= self.backbone(x)\n",
        "    x= self.classifier(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tC2qAy2b_3KO"
      },
      "source": [
        "# Create the loss and optmiser\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "DGJbtSC3EcHy"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
          ]
        }
      ],
      "source": [
        "model = Model(\n",
        "    input_channels=3,\n",
        "    output_channels=256,\n",
        "    middle_channels=64,\n",
        "    hidden_channels=256,\n",
        "    num_blocks=7,\n",
        "    k=4,\n",
        "    r=4,\n",
        "    num_classes=10,\n",
        "    use_mlp=True\n",
        ")\n",
        "\n",
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "    elif isinstance(m, nn.BatchNorm2d):\n",
        "        nn.init.constant_(m.weight, 1)\n",
        "        nn.init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):\n",
        "        nn.init.kaiming_normal_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4, momentum=0.9)\n",
        "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[60, 120, 160], gamma=0.2)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5, verbose=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlNFWcuJ_8dY"
      },
      "source": [
        "# Training & Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdK9bHyHRaVt",
        "outputId": "f59cac49-555d-4148-9435-d29fb3076c79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/782 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2.2669 | Accuracy: 23.25%\n",
            "Val   Loss: 1.9472 | Accuracy: 33.85%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 2/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.8792 | Accuracy: 34.50%\n",
            "Val   Loss: 1.6923 | Accuracy: 43.22%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 3/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.7743 | Accuracy: 40.08%\n",
            "Val   Loss: 1.6770 | Accuracy: 45.07%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 4/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.6975 | Accuracy: 44.71%\n",
            "Val   Loss: 1.4743 | Accuracy: 54.27%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 5/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.6361 | Accuracy: 47.77%\n",
            "Val   Loss: 1.4573 | Accuracy: 56.34%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 6/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.5884 | Accuracy: 50.39%\n",
            "Val   Loss: 1.3912 | Accuracy: 59.49%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 7/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.5439 | Accuracy: 52.81%\n",
            "Val   Loss: 1.3448 | Accuracy: 61.33%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 8/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.5186 | Accuracy: 53.93%\n",
            "Val   Loss: 1.2955 | Accuracy: 63.93%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 9/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.4877 | Accuracy: 55.40%\n",
            "Val   Loss: 1.3397 | Accuracy: 62.73%\n",
            "No improvement for 1 epochs.\n",
            "\n",
            "Epoch 10/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.4513 | Accuracy: 57.07%\n",
            "Val   Loss: 1.2296 | Accuracy: 66.34%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 11/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.4295 | Accuracy: 58.56%\n",
            "Val   Loss: 1.1972 | Accuracy: 69.13%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 12/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.4055 | Accuracy: 59.62%\n",
            "Val   Loss: 1.1680 | Accuracy: 69.92%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 13/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.3769 | Accuracy: 61.02%\n",
            "Val   Loss: 1.1643 | Accuracy: 69.83%\n",
            "No improvement for 1 epochs.\n",
            "\n",
            "Epoch 14/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.3657 | Accuracy: 61.71%\n",
            "Val   Loss: 1.0999 | Accuracy: 73.64%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 15/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.3454 | Accuracy: 62.70%\n",
            "Val   Loss: 1.1260 | Accuracy: 72.30%\n",
            "No improvement for 1 epochs.\n",
            "\n",
            "Epoch 16/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.3252 | Accuracy: 63.58%\n",
            "Val   Loss: 1.1029 | Accuracy: 73.50%\n",
            "No improvement for 2 epochs.\n",
            "\n",
            "Epoch 17/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.3179 | Accuracy: 63.90%\n",
            "Val   Loss: 1.0808 | Accuracy: 74.62%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 18/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.3012 | Accuracy: 64.94%\n",
            "Val   Loss: 1.0742 | Accuracy: 74.84%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 19/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.2885 | Accuracy: 65.21%\n",
            "Val   Loss: 1.0669 | Accuracy: 75.67%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 20/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.2818 | Accuracy: 65.94%\n",
            "Val   Loss: 1.0218 | Accuracy: 76.88%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 21/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.2766 | Accuracy: 66.22%\n",
            "Val   Loss: 1.0313 | Accuracy: 76.84%\n",
            "No improvement for 1 epochs.\n",
            "\n",
            "Epoch 22/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.2628 | Accuracy: 66.53%\n",
            "Val   Loss: 1.0272 | Accuracy: 77.10%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 23/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.2536 | Accuracy: 67.35%\n",
            "Val   Loss: 1.0679 | Accuracy: 75.27%\n",
            "No improvement for 1 epochs.\n",
            "\n",
            "Epoch 24/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.2524 | Accuracy: 67.20%\n",
            "Val   Loss: 1.0038 | Accuracy: 77.70%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 25/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.2386 | Accuracy: 68.00%\n",
            "Val   Loss: 0.9944 | Accuracy: 78.23%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 26/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.2380 | Accuracy: 67.88%\n",
            "Val   Loss: 1.0241 | Accuracy: 77.41%\n",
            "No improvement for 1 epochs.\n",
            "\n",
            "Epoch 27/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.2371 | Accuracy: 67.79%\n",
            "Val   Loss: 0.9987 | Accuracy: 78.37%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 28/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.2262 | Accuracy: 68.37%\n",
            "Val   Loss: 0.9716 | Accuracy: 79.10%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 29/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.2198 | Accuracy: 68.68%\n",
            "Val   Loss: 0.9727 | Accuracy: 79.37%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 30/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.2128 | Accuracy: 68.85%\n",
            "Val   Loss: 1.0544 | Accuracy: 75.94%\n",
            "No improvement for 1 epochs.\n",
            "\n",
            "Epoch 31/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.2115 | Accuracy: 69.25%\n",
            "Val   Loss: 0.9925 | Accuracy: 78.68%\n",
            "No improvement for 2 epochs.\n",
            "\n",
            "Epoch 32/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.2049 | Accuracy: 69.48%\n",
            "Val   Loss: 1.0072 | Accuracy: 77.97%\n",
            "No improvement for 3 epochs.\n",
            "\n",
            "Epoch 33/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1985 | Accuracy: 69.81%\n",
            "Val   Loss: 0.9764 | Accuracy: 79.15%\n",
            "No improvement for 4 epochs.\n",
            "\n",
            "Epoch 34/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.2013 | Accuracy: 69.68%\n",
            "Val   Loss: 0.9590 | Accuracy: 79.31%\n",
            "No improvement for 5 epochs.\n",
            "\n",
            "Epoch 35/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1845 | Accuracy: 70.44%\n",
            "Val   Loss: 0.9436 | Accuracy: 81.07%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 36/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1871 | Accuracy: 70.23%\n",
            "Val   Loss: 0.9463 | Accuracy: 80.65%\n",
            "No improvement for 1 epochs.\n",
            "\n",
            "Epoch 37/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1824 | Accuracy: 70.27%\n",
            "Val   Loss: 0.9413 | Accuracy: 80.59%\n",
            "No improvement for 2 epochs.\n",
            "\n",
            "Epoch 38/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1787 | Accuracy: 70.64%\n",
            "Val   Loss: 0.9665 | Accuracy: 79.08%\n",
            "No improvement for 3 epochs.\n",
            "\n",
            "Epoch 39/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1759 | Accuracy: 70.80%\n",
            "Val   Loss: 0.9300 | Accuracy: 81.04%\n",
            "No improvement for 4 epochs.\n",
            "\n",
            "Epoch 40/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1698 | Accuracy: 71.07%\n",
            "Val   Loss: 0.9902 | Accuracy: 78.51%\n",
            "No improvement for 5 epochs.\n",
            "\n",
            "Epoch 41/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1714 | Accuracy: 71.36%\n",
            "Val   Loss: 0.9415 | Accuracy: 81.20%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 42/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1678 | Accuracy: 71.20%\n",
            "Val   Loss: 0.9317 | Accuracy: 81.21%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 43/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1634 | Accuracy: 71.31%\n",
            "Val   Loss: 0.9412 | Accuracy: 81.07%\n",
            "No improvement for 1 epochs.\n",
            "\n",
            "Epoch 44/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1609 | Accuracy: 71.58%\n",
            "Val   Loss: 0.9322 | Accuracy: 81.42%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 45/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1605 | Accuracy: 71.44%\n",
            "Val   Loss: 0.9633 | Accuracy: 79.66%\n",
            "No improvement for 1 epochs.\n",
            "\n",
            "Epoch 46/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1537 | Accuracy: 72.01%\n",
            "Val   Loss: 0.9170 | Accuracy: 81.81%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 47/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1595 | Accuracy: 71.51%\n",
            "Val   Loss: 0.9178 | Accuracy: 82.12%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 48/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1555 | Accuracy: 71.79%\n",
            "Val   Loss: 0.9567 | Accuracy: 80.30%\n",
            "No improvement for 1 epochs.\n",
            "\n",
            "Epoch 49/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1459 | Accuracy: 72.09%\n",
            "Val   Loss: 0.9243 | Accuracy: 81.71%\n",
            "No improvement for 2 epochs.\n",
            "\n",
            "Epoch 50/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1464 | Accuracy: 72.26%\n",
            "Val   Loss: 0.9636 | Accuracy: 80.38%\n",
            "No improvement for 3 epochs.\n",
            "\n",
            "Epoch 51/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1397 | Accuracy: 72.42%\n",
            "Val   Loss: 0.9117 | Accuracy: 82.07%\n",
            "No improvement for 4 epochs.\n",
            "\n",
            "Epoch 52/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1386 | Accuracy: 72.52%\n",
            "Val   Loss: 0.9158 | Accuracy: 81.82%\n",
            "No improvement for 5 epochs.\n",
            "\n",
            "Epoch 53/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1390 | Accuracy: 72.42%\n",
            "Val   Loss: 0.9063 | Accuracy: 82.24%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 54/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1293 | Accuracy: 72.97%\n",
            "Val   Loss: 0.9337 | Accuracy: 81.11%\n",
            "No improvement for 1 epochs.\n",
            "\n",
            "Epoch 55/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1341 | Accuracy: 72.84%\n",
            "Val   Loss: 0.9115 | Accuracy: 82.12%\n",
            "No improvement for 2 epochs.\n",
            "\n",
            "Epoch 56/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1330 | Accuracy: 72.64%\n",
            "Val   Loss: 0.9022 | Accuracy: 82.94%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 57/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1324 | Accuracy: 72.75%\n",
            "Val   Loss: 0.8903 | Accuracy: 83.28%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 58/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1262 | Accuracy: 73.28%\n",
            "Val   Loss: 0.9112 | Accuracy: 82.34%\n",
            "No improvement for 1 epochs.\n",
            "\n",
            "Epoch 59/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1257 | Accuracy: 72.82%\n",
            "Val   Loss: 0.9214 | Accuracy: 81.65%\n",
            "No improvement for 2 epochs.\n",
            "\n",
            "Epoch 60/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1254 | Accuracy: 73.02%\n",
            "Val   Loss: 0.9092 | Accuracy: 82.27%\n",
            "No improvement for 3 epochs.\n",
            "\n",
            "Epoch 61/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1230 | Accuracy: 73.34%\n",
            "Val   Loss: 0.9045 | Accuracy: 82.54%\n",
            "No improvement for 4 epochs.\n",
            "\n",
            "Epoch 62/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1225 | Accuracy: 73.22%\n",
            "Val   Loss: 0.8935 | Accuracy: 82.72%\n",
            "No improvement for 5 epochs.\n",
            "\n",
            "Epoch 63/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1192 | Accuracy: 73.43%\n",
            "Val   Loss: 0.8871 | Accuracy: 83.50%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 64/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1175 | Accuracy: 73.35%\n",
            "Val   Loss: 0.8845 | Accuracy: 83.11%\n",
            "No improvement for 1 epochs.\n",
            "\n",
            "Epoch 65/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1205 | Accuracy: 73.22%\n",
            "Val   Loss: 0.8766 | Accuracy: 83.45%\n",
            "No improvement for 2 epochs.\n",
            "\n",
            "Epoch 66/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1186 | Accuracy: 73.34%\n",
            "Val   Loss: 0.9051 | Accuracy: 82.09%\n",
            "No improvement for 3 epochs.\n",
            "\n",
            "Epoch 67/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1178 | Accuracy: 73.54%\n",
            "Val   Loss: 0.9168 | Accuracy: 81.94%\n",
            "No improvement for 4 epochs.\n",
            "\n",
            "Epoch 68/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1190 | Accuracy: 73.51%\n",
            "Val   Loss: 0.8716 | Accuracy: 83.90%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 69/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1128 | Accuracy: 73.54%\n",
            "Val   Loss: 0.9170 | Accuracy: 81.64%\n",
            "No improvement for 1 epochs.\n",
            "\n",
            "Epoch 70/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1043 | Accuracy: 73.92%\n",
            "Val   Loss: 0.8809 | Accuracy: 83.57%\n",
            "No improvement for 2 epochs.\n",
            "\n",
            "Epoch 71/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1093 | Accuracy: 73.81%\n",
            "Val   Loss: 0.8858 | Accuracy: 83.02%\n",
            "No improvement for 3 epochs.\n",
            "\n",
            "Epoch 72/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1094 | Accuracy: 73.70%\n",
            "Val   Loss: 0.8754 | Accuracy: 83.80%\n",
            "No improvement for 4 epochs.\n",
            "\n",
            "Epoch 73/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1041 | Accuracy: 73.98%\n",
            "Val   Loss: 0.8715 | Accuracy: 84.16%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 74/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1056 | Accuracy: 73.71%\n",
            "Val   Loss: 0.8773 | Accuracy: 83.95%\n",
            "No improvement for 1 epochs.\n",
            "\n",
            "Epoch 75/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1011 | Accuracy: 74.22%\n",
            "Val   Loss: 0.8728 | Accuracy: 84.23%\n",
            "Saved best model.\n",
            "\n",
            "Epoch 76/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1010 | Accuracy: 74.18%\n",
            "Val   Loss: 0.9000 | Accuracy: 82.95%\n",
            "No improvement for 1 epochs.\n",
            "\n",
            "Epoch 77/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1046 | Accuracy: 74.08%\n",
            "Val   Loss: 0.9104 | Accuracy: 82.14%\n",
            "No improvement for 2 epochs.\n",
            "\n",
            "Epoch 78/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1002 | Accuracy: 74.27%\n",
            "Val   Loss: 0.8880 | Accuracy: 83.57%\n",
            "No improvement for 3 epochs.\n",
            "\n",
            "Epoch 79/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.0991 | Accuracy: 74.38%\n",
            "Val   Loss: 0.8922 | Accuracy: 83.26%\n",
            "No improvement for 4 epochs.\n",
            "\n",
            "Epoch 80/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1001 | Accuracy: 74.27%\n",
            "Val   Loss: 0.8899 | Accuracy: 83.54%\n",
            "No improvement for 5 epochs.\n",
            "\n",
            "Epoch 81/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.0972 | Accuracy: 74.35%\n",
            "Val   Loss: 0.8862 | Accuracy: 83.47%\n",
            "No improvement for 6 epochs.\n",
            "\n",
            "Epoch 82/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                           \r"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[68], line 61\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     val_loss, val_acc \u001b[38;5;241m=\u001b[39m evaluate(model, testloader, criterion, device)\n\u001b[1;32m     63\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep(val_acc)  \u001b[38;5;66;03m# Adjust learning rate based on validation accuracy\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[68], line 23\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, loader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     20\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 23\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     26\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[66], line 24\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[0;32m---> 24\u001b[0m   x\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m   x\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone(x)\n\u001b[1;32m     26\u001b[0m   x\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(x)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[61], line 29\u001b[0m, in \u001b[0;36mStem.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[0;32m---> 29\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Set up device \n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Save model\n",
        "model.to(device)\n",
        "\n",
        "# Log training \n",
        "train_losses, val_losses = [], []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "# Training and Validation Loops \n",
        "def train(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    return running_loss / len(loader), 100 * correct / total\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    return loss / len(loader), 100 * correct / total\n",
        "\n",
        "# Main Loop \n",
        "patience = 15  # Number of epochs to wait for improvement\n",
        "early_stop_counter = 0 # Counter for early stopping\n",
        "epochs = 200\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "    train_loss, train_acc = train(model, trainloader, criterion, optimizer, device)\n",
        "    val_loss, val_acc = evaluate(model, testloader, criterion, device)\n",
        "    scheduler.step(val_acc)  # Adjust learning rate based on validation accuracy\n",
        "\n",
        "\n",
        "    # Log metrics\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    val_accuracies.append(val_acc)\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Accuracy: {train_acc:.2f}%\")\n",
        "    print(f\"Val   Loss: {val_loss:.4f} | Accuracy: {val_acc:.2f}%\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        early_stop_counter=0\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "        print(\"Saved best model.\")\n",
        "    else:\n",
        "        early_stop_counter += 1\n",
        "        print(f\"No improvement for {early_stop_counter} epochs.\")\n",
        "\n",
        "    if early_stop_counter >= patience:\n",
        "        print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
        "        break\n",
        "print(\"\\nTraining Complete\")\n",
        "\n",
        "# Print Final Averages \n",
        "avg_train_loss = sum(train_losses) / len(train_losses)\n",
        "avg_val_loss = sum(val_losses) / len(val_losses)\n",
        "avg_train_acc = sum(train_accuracies) / len(train_accuracies)\n",
        "avg_val_acc = sum(val_accuracies) / len(val_accuracies)\n",
        "\n",
        "print(\"\\nFinal Averages Over All Epochs\")\n",
        "print(f\"Average Train Loss: {avg_train_loss:.4f}\")\n",
        "print(f\"Average Train Accuracy: {avg_train_acc:.2f}%\")\n",
        "print(f\"Average Val   Loss: {avg_val_loss:.4f}\")\n",
        "print(f\"Average Val   Accuracy: {avg_val_acc:.2f}%\")\n",
        "\n",
        "\n",
        "# Plot results\n",
        "\n",
        "# Plot Loss\n",
        "plt.figure()\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.title(\"Loss Curve\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.savefig(\"loss_curve.png\")\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.figure()\n",
        "plt.plot(train_accuracies, label='Train Accuracy')\n",
        "plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "plt.title(\"Accuracy Curve\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.savefig(\"accuracy_curve.png\")\n",
        "\n",
        "print(\"Plots saved: loss_curve.png and accuracy_curve.png\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
